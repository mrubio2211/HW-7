---
title: "Hw 7"
author: "Maria Rubio Navarro"
date: "12/3/2024"
output:
  pdf_document: default
  html_document:
    number_sections: true
---

# 

Recall that in class we showed that for randomized response differential privacy based on a fair coin (that is a coin that lands heads up with probability $0.5$), the estimated proportion of incriminating observations $\hat{P}$ ^[in class this was the estimated proportion of students having actually cheated] was given by $\hat{P} = 2\hat{\pi}-\frac{1}{2}$ where $\hat{\pi}$ is the proportion of people answering affirmative to the incriminating question.  

I want you to generalize this result for a potentially biased coin. That is, for a differentially private mechanism that uses a coin landing heads up with probability $0 \leq \theta \leq 1$, find an estimate $\hat{P}$ for the proportion of incriminating observations. This expression should be in terms of $\theta$ and $\hat{\pi}$.

```{r}
theta <- 0.7  
pi_hat <- 0.6 

P_hat <- (pi_hat - (1 - theta)) / (2 * theta - 1)

cat("The estimated proportion of incriminating observations (P_hat) is:", P_hat, "\n")


#
Next, show that this expression reduces to our result from class in the special case where $\theta = \frac{1}{2}$.

theta <- 0.5
pi_hat <- 0.6 

P_hat <- (pi_hat - (1 - theta)) / (2 * theta - 1)

cat("The estimated proportion of incriminating observations ($P_{\\text{hat}}$) is:", P_hat, "\n")

#
Part of having an explainable model is being able to implement the algorithm from scratch.  Let's try and do this with `KNN`.  Write a function entitled `chebychev` that takes in two vectors and outputs the Chebychev or $L^\infty$ distance between said vectors.  I will test your function on two vectors below.  Then, write a `nearest_neighbors` function that finds the user specified $k$ nearest neighbors according to a user specified distance function (in this case $L^\infty$) to a user specified data point observation.  

```{r, eval = FALSE}
#student input
#chebychev function
#nearest_neighbors function


x<- c(3,4,5)
y<-c(7,10,1)
cheby(x,y)

```

chebychev <- function(vec1, vec2) {
  
  return(max(abs(vec1 - vec2)))
}

nearest_neighbors <- function(data, target_point, k, distance_function) {
 
  distances <- apply(data, 1, function(row) distance_function(row, target_point))
  
  nearest_indices <- order(distances)[1:k]

  return(data[nearest_indices, ])
}

x <- c(3, 4, 5)
y <- c(7, 10, 1)

cat("Chebychev distance:", chebychev(x, y), "\n")

data <- matrix(c(3, 4, 5, 7, 10, 1, 2, 8, 6), nrow = 3, byrow = TRUE) 
target_point <- c(4, 9, 5) 
k <- 2 

neighbors <- nearest_neighbors(data, target_point, k, chebychev)
cat("Nearest neighbors:\n")
print(neighbors)

#
Finally create a `knn_classifier` function that takes the nearest neighbors specified from the above functions and assigns a class label based on the mode class label within these nearest neighbors.  I will then test your functions by finding the five nearest neighbors to the very last observation in the `iris` dataset according to the `chebychev` distance and classifying this function accordingly.  

```{r, eval = FALSE}
library(class)
df <- data(iris) 
#student input


#data less last observation
x = iris[1:(nrow(iris)-1),]
#observation to be classified
obs = iris[nrow(iris),]

#find nearest neighbors
ind = nearest_neighbors(x[,1:4], obs[,1:4],5, chebychev)[[1]]
as.matrix(x[ind,1:4])
obs[,1:4]
knn_classifier(x[ind,], 'Species')
obs[,'Species']

```

chebychev <- function(vec1, vec2) {
  return(max(abs(vec1 - vec2)))
}

nearest_neighbors <- function(data, target_point, k, distance_function) {
  distances <- apply(data, 1, function(row) distance_function(row, target_point))
  nearest_indices <- order(distances)[1:k]
  return(nearest_indices)  
}

knn_classifier <- function(neighbors, class_column_name) {
 
  mode_class <- as.character(names(sort(table(neighbors[, class_column_name]), decreasing = TRUE)[1]))
  return(mode_class)
}

data(iris)

x <- iris[1:(nrow(iris)-1),]

obs <- iris[nrow(iris),]

ind <- nearest_neighbors(x[,1:4], obs[,1:4], 5, chebychev)  
as.matrix(x[ind, 1:4])  

obs[, 1:4]  

predicted_class <- knn_classifier(x[ind,], 'Species')
cat("Predicted class label:", predicted_class, "\n")

obs[, 'Species']  

# 
Interpret this output.  Did you get the correct classification?  Also, if you specified $K=5$, why do you have $7$ observations included in the output dataframe?

The number of observations can be greater than 5 due to ties in the distances, which causes the algorithm to include more than 5 neighbors. The classification is correct if the predicted class matches the true class of the observation. If not, the model made an incorrect prediction.


#
Earlier in this unit we learned about Google's DeepMind assisting in the management of acute kidney injury.  Assistance in the health care sector is always welcome, particularly if it benefits the well-being of the patient.  Even so, algorithmic assistance necessitates the acquisition and retention of sensitive health care data.  With this in mind, who should be privy to this sensitive information?  In particular, is data transfer allowed if the company managing the software is subsumed?  Should the data be made available to insurance companies who could use this to better calibrate their actuarial risk but also deny care?  Stake a position and defend it using principles discussed from the class.  

Only those who require it for medical reasons should have access to sensitive health information. Data transfer should only be permitted with robust safeguards if a company is acquired. Without patient agreement, insurance firms shouldn't access this data since it can result in discrimination. Limiting access to safeguard patients from harm is supported by ethical ideals such as autonomy and justice.

#
I have described our responsibility to proper interpretation as an *obligation* or *duty*.  How might a Kantian Deontologist defend such a claim?  

A Kantian Deontologist would support the assertion by pointing out that we have an obligation to correctly interpret information since it is consistent with morality and respect for other people. Kant believed that deeds that respect the dignity of others and can be universalized are ethically correct. This obligation would be broken by misinterpreting information since it could deceive or hurt other people, which is against the idea that people should be treated as goals in and of themselves rather than just as means.


